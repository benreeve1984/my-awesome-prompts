Research the latest SOTA tools that a team of LLM agent developers (quant analysts who are LLM users designing solutions for users, not AI engineers building the foundation models, nor ML Ops deploying at scale). They need to be able to quickly design (sketch out), experiment, test, evaluate, refine, and expose to users in sandbox mode for testing and feedback. This all needs to be done in a way that testing and gathering all the data produced is easy (strong focus on test driven design of the agents, strong feedback loops not wasting useful user data, etc.). The team is small so will need to be able to develop rapidly, but can't spent millions on setup, e.g. solutions like Azure OpenAi Playground, AWS Bedrock, Databricks, LangGraph Studio, etc. could be quick to deploy.

Do an analysis of what is currently available: what does it do, what is it good for, what is it less good for?